{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemAndRemovePuncAndStopWords(data):\n",
    "    \n",
    "    tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "    sno = nltk.stem.SnowballStemmer('english')\n",
    "    \n",
    "    for tweet in data:\n",
    "        for word in tokenizer.tokenize(tweet):\n",
    "            sno.stem(word)\n",
    "    \n",
    "    \n",
    "    return [\" \".join([sno.stem(word) for word in tokenizer.tokenize(tweet)]for tweet in data)] \n",
    "\n",
    "#if word not in nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Read in the data to a pandas DataFrame\n",
    "train = pd.read_csv(\"Tweets/tweet4-even-train.csv\", encoding=\"utf-8\")\n",
    "test = pd.read_csv(\"Tweets/tweet4-even-test.csv\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildFeatureSet(data):\n",
    "    vectorizer = CountVectorizer(\n",
    "        lowercase=True,\n",
    "        stop_words=None,\n",
    "        max_df=25,\n",
    "        min_df=1,\n",
    "        max_features=None,\n",
    "        binary=True,\n",
    "        ngram_range=(2,2)\n",
    "    )\n",
    "\n",
    "    features = vectorizer.fit_transform(data['text'].values.astype('U')).toarray()\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    print(\"Vocab size: {}\".format(len(feature_names)))\n",
    "\n",
    "    return list(zip(\n",
    "        [  # zip a list of vocab dicts with their genre\n",
    "            {\n",
    "                word: bool(features[row][idx])  # A word and its presence in this song\n",
    "                for idx, word in enumerate(feature_names)  # Go through all the words in the vocab\n",
    "            } for row in range(len(features))  # Each dict has |vocab| entries: true or false if the song has that word\n",
    "        ],data['id']\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 87490\n"
     ]
    }
   ],
   "source": [
    "train = buildFeatureSet(train)\n",
    "test = buildFeatureSet(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                minister = True            Trump : Ellen  =     15.9 : 1.0\n                   prime = True            Trump : Ellen  =     15.3 : 1.0\n                  boring = True             Elon : Trump  =     14.5 : 1.0\n                  attack = True            Trump : Elon   =     14.2 : 1.0\n                   badly = True            Trump : Elon   =     14.2 : 1.0\n               education = True            Obama : Ellen  =     13.9 : 1.0\n                 weather = True             Elon : Obama  =     13.8 : 1.0\n                    roof = True             Elon : Trump  =     13.8 : 1.0\n                  design = True             Elon : Trump  =     13.8 : 1.0\n             interviewed = True            Trump : Obama  =     13.7 : 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7829099307159353"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(train)\n",
    "\n",
    "classifier.show_most_informative_features()\n",
    "nltk.classify.accuracy(classifier, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}